[{"model": "blog.tag", "pk": 1, "fields": {"slug": "Python"}}, {"model": "blog.tag", "pk": 2, "fields": {"slug": "shell"}}, {"model": "blog.tag", "pk": 3, "fields": {"slug": "Django"}}, {"model": "blog.tag", "pk": 4, "fields": {"slug": "AWS"}}, {"model": "blog.tag", "pk": 5, "fields": {"slug": "OSX"}}, {"model": "blog.tag", "pk": 6, "fields": {"slug": "ElasticSearch"}}, {"model": "blog.tag", "pk": 7, "fields": {"slug": "Docker"}}, {"model": "blog.tag", "pk": 8, "fields": {"slug": "Jira"}}, {"model": "blog.tag", "pk": 9, "fields": {"slug": "Ubuntu"}}, {"model": "blog.tag", "pk": 10, "fields": {"slug": "Gunicorn"}}, {"model": "blog.tag", "pk": 11, "fields": {"slug": "Nginx"}}, {"model": "blog.tag", "pk": 12, "fields": {"slug": "virtualenv"}}, {"model": "blog.tag", "pk": 13, "fields": {"slug": "Anaconda"}}, {"model": "blog.tag", "pk": 14, "fields": {"slug": "Supervisor"}}, {"model": "blog.tag", "pk": 15, "fields": {"slug": "PostgreSQL"}}, {"model": "blog.tag", "pk": 16, "fields": {"slug": "Java"}}, {"model": "blog.entry", "pk": 1, "fields": {"title": "Find most used history command", "body": "``` shell\r\n$ awk '{print $1}' ~/.bash_history | sort | uniq -c | sort -n\r\n```", "slug": "find-most-used-history-command", "publish": true, "created": "2016-07-27T13:20:16.376Z", "modified": "2016-08-19T09:20:07.425Z", "tags": [2]}}, {"model": "blog.entry", "pk": 2, "fields": {"title": "Create big files with dd", "body": "Use dd in Unix to create files with a size of 2.7 GB.\r\n``` shell\r\n#!/bin/ksh\r\ndir=/this/is/my/outputdir/\r\nnumGig=2.7\r\nfactor=1024\r\nmemLimit=$(expr $numGig*$factor*$factor*$factor | bc)\r\ncd $dir\r\nfor i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ; do\r\n   dd if=/dev/urandom of=dummy_$i.xml count=204800 bs=$factor\r\ndone\r\n```", "slug": "create-big-files-dd", "publish": true, "created": "2016-07-28T22:11:51.246Z", "modified": "2016-08-01T23:14:58.566Z", "tags": [2]}}, {"model": "blog.entry", "pk": 4, "fields": {"title": "Simple webcrawling in Python ", "body": "```python\r\n\"\"\" samples/crawl_01.py \"\"\"\r\n################################################################################\r\n# Application:      WebParser example 01\r\n# File:             samples/crawl_01.py\r\n# Goal:\r\n# Input:\r\n# Output:\r\n# Example:\r\n#\r\n# History:          2016-06-27 - JJ     Creation of the file\r\n#\r\n################################################################################\r\n\r\n################################################################################\r\n# Imports\r\n################################################################################\r\nimport lxml.html\r\nimport urllib2\r\n\r\n################################################################################\r\n# Definitions\r\n################################################################################\r\nHEADER = {'Accept-Language': 'nl-NL',\r\n          'User-Agent': \"\"\"Mozilla/5.0 (Windows; U;\r\n                                    Windows NT 6.1;\r\n                                    nl-NL;\r\n                                    rv:1.9.1.5)\r\n                       Gecko/20091102 Firefox/3.5.5 (.NET CLR 3.5.30729);\r\n                       nl-NL\"\"\"}\r\n################################################################################\r\n# Classes\r\n################################################################################\r\nclass WebParser(object):\r\n    \"\"\" Definition of the WebParser \"\"\"\r\n    def __init__(self, *args, **kwargs):\r\n        \"\"\" Initialize the WebParser \"\"\"\r\n        super(WebParser, self).__init__(*args, **kwargs)\r\n\r\n    @staticmethod\r\n    def parse_page(url):\r\n        \"\"\" Open URL and return the element tree of the page \"\"\"\r\n        req = urllib2.Request(url, headers=HEADER)\r\n        data = urllib2.urlopen(req).read()\r\n        tree = lxml.html.fromstring(data)\r\n        return tree\r\n\r\n    @staticmethod\r\n    def find_css_element(etree, element):\r\n        \"\"\" Find an element in the element tree and return it \"\"\"\r\n        return etree.cssselect(element)\r\n\r\n################################################################################\r\n# Functions\r\n################################################################################\r\ndef main():\r\n    \"\"\" Main function \"\"\"\r\n    parser = WebParser()\r\n    etree = parser.parse_page('http://isitweekendyet.com/')\r\n    divs = parser.find_css_element(etree, 'div')\r\n    print divs[0].text.strip()\r\n\r\n################################################################################\r\n# main\r\n################################################################################\r\nif __name__ == \"__main__\":\r\n    main()\r\n```", "slug": "simple-webcrawling-python", "publish": true, "created": "2016-07-29T00:16:51.650Z", "modified": "2016-07-31T14:33:03.939Z", "tags": [2]}}, {"model": "blog.entry", "pk": 5, "fields": {"title": "Mount Amazon EC as local folder", "body": "``` shell\r\n$ sshfs ubuntu@ec2-34-56-7-89.eu-central-1.compute.amazonaws.com:/home/ubuntu/ ~/AmazonEC2/ -oauto_cache,reconnect,defer_permissions,noappledouble,negative_vncache\r\n```", "slug": "mount-amazon-ec-local-folder", "publish": true, "created": "2016-07-30T18:56:37.576Z", "modified": "2016-08-19T09:19:56.712Z", "tags": [2]}}, {"model": "blog.entry", "pk": 6, "fields": {"title": "Send attachment from command line", "body": "``` shell\r\n$ echo 'Mail with attachment' | mutt -a \"/file/to/add/\" -s \"FYI: See attachment\" -- name@email.com\r\n```", "slug": "send-attachment-command-line", "publish": true, "created": "2016-07-30T19:03:24.557Z", "modified": "2016-08-19T09:19:46.403Z", "tags": [2]}}, {"model": "blog.entry", "pk": 7, "fields": {"title": "Webcrawling in Python using Selenium", "body": "This is a simple script to crawl information from a website when the content is dynamically loaded. For the script to work, fourapplications need to be installed first.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo pip install selenium\r\njitsejan@jjsvps:~$ sudo apt-get install firefox\r\njitsejan@jjsvps:~$ sudo pip install pyvirtualdisplay\r\njitsejan@jjsvps:~$ sudo apt-get install xvfb\r\n```\r\nNow the following script can be used.\r\n```\r\n\"\"\" samples/crawl_02.py \"\"\"\r\n################################################################################\r\n# Application:      WebParser example 02\r\n# File:             samples/crawl_01.py\r\n# Goal:             Retrieve content when JavaScript is used in page\r\n# Input:\r\n# Output:\r\n# Example:\r\n#\r\n# History:          2016-06-27 - JJ     Creation of the file\r\n#\r\n################################################################################\r\n\r\n################################################################################\r\n# Imports\r\n################################################################################\r\nimport lxml.html\r\nimport urllib2\r\n\r\nfrom pyvirtualdisplay import Display\r\nfrom selenium import webdriver\r\n\r\n################################################################################\r\n# Definitions\r\n################################################################################\r\nHEADER = {'Accept-Language': 'nl-NL',\r\n          'User-Agent': \"\"\"Mozilla/5.0 (Windows; U;\r\n                                    Windows NT 6.1;\r\n                                    nl-NL;\r\n                                    rv:1.9.1.5)\r\n                       Gecko/20091102 Firefox/3.5.5 (.NET CLR 3.5.30729);\r\n                       nl-NL\"\"\"}\r\n################################################################################\r\n# Classes\r\n################################################################################\r\nclass WebParser(object):\r\n    \"\"\" Definition of the WebParser \"\"\"\r\n    def __init__(self, *args, **kwargs):\r\n        \"\"\" Initialize the WebParser \"\"\"\r\n        super(WebParser, self).__init__(*args, **kwargs)\r\n\r\n    @staticmethod\r\n    def parse_page(url):\r\n        \"\"\" Open URL and return the element tree of the page \"\"\"\r\n        display = Display(visible=0, size=(1920, 1080))\r\n        display.start()\r\n        browser = webdriver.Firefox()\r\n        browser.get(url)\r\n        data = browser.page_source\r\n        tree = lxml.html.fromstring(data)\r\n        browser.quit()\r\n        display.stop()\r\n        return tree\r\n\r\n    @staticmethod\r\n    def find_css_element(etree, element):\r\n        \"\"\" Find an element in the element tree and return it \"\"\"\r\n        return etree.cssselect(element)\r\n\r\n################################################################################\r\n# Functions\r\n################################################################################\r\ndef main():\r\n    \"\"\" Main function \"\"\"\r\n    parser = WebParser()\r\n    etree = parser.parse_page('http://isitweekendalready.com')\r\n    divs = parser.find_css_element(etree, '#result')\r\n    print divs[0].text.strip()\r\n\r\n################################################################################\r\n# main\r\n################################################################################\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n### Update 05-Oct-2016\r\nRecently I discovered that Selenium does not work well with newer versions of Firefox. Therefore I had to downgrade Firefox to be able to use Selenium.\r\n\r\n``` shell\r\njitsejan@jjsvps:~$ firefox -v\r\njitsejan@jjsvps:~$ sudo apt-get purge firefox\r\njitsejan@jjsvps:~$ wget sourceforge.net/projects/ubuntuzilla/files/mozilla/apt/pool/main/f/firefox-mozilla-build/firefox-mozilla-build_39.0.3-0ubuntu1_amd64.deb\r\njitsejan@jjsvps:~$ sudo dpkg -i firefox-mozilla-build_39.0.3-0ubuntu1_amd64.deb \r\njitsejan@jjsvps:~$ rm firefox-mozilla-build_39.0.3-0ubuntu1_amd64.deb \r\njitsejan@jjsvps:~$ firefox -v\r\n\r\n```", "slug": "webcrawling-python-using-selenium", "publish": true, "created": "2016-07-30T19:07:27.906Z", "modified": "2016-10-05T08:13:59.973Z", "tags": [1]}}, {"model": "blog.entry", "pk": 8, "fields": {"title": "Show all debug information in Django", "body": "```\r\n<pre> {% filter force_escape %} {% debug %} {% endfilter %} </pre>\r\n```", "slug": "show-all-debug-information-django", "publish": true, "created": "2016-07-30T21:25:04.472Z", "modified": "2016-07-30T21:25:40.969Z", "tags": [3]}}, {"model": "blog.entry", "pk": 9, "fields": {"title": "Change the last modified time of a file", "body": "This script will change the last modified time of a file in the current directory to 4 days back.\r\n``` shell\r\n#!/bin/ksh \r\nnumDays=4\r\ndiff=86400*$numDays\r\nexport diff\r\nnewDate=$(perl -e 'use POSIX; print strftime \"%Y%m%d%H%M\", localtime time-$ENV{diff};')\r\nlastFile=$(ls -lt | egrep -v ^d | tail -1 | awk ' { print $9 } ')\r\ntouch -t $newDate $lastFile\r\n```", "slug": "change-last-modified-time-file", "publish": true, "created": "2016-07-30T23:24:08.871Z", "modified": "2016-07-31T02:42:21.495Z", "tags": [2]}}, {"model": "blog.entry", "pk": 10, "fields": {"title": "Setting up an AWS EC instance", "body": "* Go to the [EC page](https://eu-central-1.console.aws.amazon.com/ec2/v2/home?region=eu-central-1#Instances:sort=instanceId)\r\n* Launch Instance\r\n* Select **Ubuntu Server 14.04 LTS (HVM), SSD Volume Type - ami-87564feb**\r\n* Select **t2.micro (Free tier eligible)**\r\n* Select **Next: Configure Instance Details**\r\n* Select **Next: Add Storage**\r\n* Select **Next: Tag Instance**\r\n* Give a _Name_ to the Instance\r\n* Select **Next: Configure Security Group**\r\n* Create a new security group\r\n* Add a _Security group name_\r\n* Add a _Description_\r\n* Add rule by clicking **Add Rule**\r\n* First rule should be **Custom TCP Rule, TCP Protocol, Port 80 for source Anywhere**\r\n* Click on **Launch**\r\n* Select **Review and launch**\r\n* In the pop-up, select **Create a new key pair**\r\n* Fill in a _Key pair name_\r\n* Download the _Key Pair_ and save in a <u>secure</u> location\r\n* Go to the [instance page](https://eu-central-1.console.aws.amazon.com/ec2/v2/home?region=eu-central-1#Instances:sort=instanceId) and wait until the machine is ready\r\n\r\n* On your computer, change the permissions of the key pair you just downloaded\r\n``` shell\r\n      $ chmod 400 keypairfile.pem\r\n```\r\n* Connect to the machine via ssh. Click on the Connect button in the instance overview for connection information\r\n``` shell\r\n      $ ssh -i keypairfile.pem ec2-xx-xx-x-xx.eu-central-1.compute.amazonaws.com\r\n```", "slug": "setting-aws-ec-instance", "publish": true, "created": "2016-07-31T02:45:01.050Z", "modified": "2016-08-19T09:17:34.023Z", "tags": [4]}}, {"model": "blog.entry", "pk": 12, "fields": {"title": "Add spacers in your OSX dock", "body": "Run this command in the terminal to add a spacer\r\n``` shell\r\n$ defaults write com.apple.dock persistent-apps -array-add '{tile-data={}; tile-type=\"spacer-tile\";}'\r\n```\r\nand restart the dock by running\r\n``` shell\r\n$ killall Dock\r\n```", "slug": "add-spacers-your-osx-dock", "publish": true, "created": "2016-07-31T14:38:10.989Z", "modified": "2016-08-19T09:17:24.572Z", "tags": [5]}}, {"model": "blog.entry", "pk": 13, "fields": {"title": "Getting started with data science in Python", "body": "#### Installation\r\nUse the [Anaconda](https://www.continuum.io/downloads \"Anaconda\") package. It will make starting with Data Science way easier, since almost all necessary packages are included and you can start right away.\r\n``` shell\r\n$ cd ~/Downloads\r\n$ wget http://repo.continuum.io/archive/Anaconda2-4.1.1-Linux-x86_64.sh\r\n$ bash Anaconda2-4.1.1-Linux-x86_64.sh\r\n$ source ~/.bashrc\r\n$ conda --version\r\n$ conda update conda\r\n```\r\n\r\n#### Examples\r\n##### Make your first Data Frame\r\n``` python\r\n#!/usr/bin/env python\r\nimport pandas as pd\r\n\r\ndf = pd.DataFrame({ 'A' : 1.,\r\n                    'B' : pd.Timestamp('20130102'),\r\n                    'C' : pd.Series(1, index=list(range(4)), dtype='float32'),\r\n                    'D' : pd.Series([1, 2, 1, 2], dtype='int32'),\r\n                    'E' : pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\r\n                    'F' : 'foo' })\r\n\r\ndf.groupby('E').sum().D\r\n```\r\n\r\n##### Create your first plots\r\nFirst update Seaborn\r\n``` shell\r\n$ conda install seaborn\r\n```\r\nNext, create a plot of an example dataset\r\n``` python\r\n#!/usr/bin/env python\r\nimport seaborn as sns\r\n\r\n# Load one of the data sets that come with seaborn\r\ntips = sns.load_dataset(\"tips\")\r\ntips.head()\r\n\r\nsns.jointplot(\"total_bill\", \"tip\", tips, kind='reg');\r\nsns.lmplot(\"total_bill\", \"tip\", tips, col=\"smoker\");\r\n```\r\n\r\n[Source](http://twiecki.github.io/blog/2014/11/18/python-for-data-science/ \"Twiecki@Github\")", "slug": "getting-started-data-science-python", "publish": true, "created": "2016-08-01T10:32:05.017Z", "modified": "2016-10-03T21:59:04.273Z", "tags": [1]}}, {"model": "blog.entry", "pk": 14, "fields": {"title": "Getting started with ElasticSearch", "body": "#### Install ElasticSearch\r\n``` shell\r\n$ mkdir ~/es\r\n$ cd ~/es\r\n$ wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.3.5/elasticsearch-2.3.5.tar.gz\r\n$ tar -xzvf elasticsearch-2.3.5.tar.gz\r\n$ cd elasticsearch-2.3.5/\r\n$ ./bin/elasticsearch -d\r\n$ curl http://127.0.0.1:9200\r\n```\r\nAt this point you should see something like\r\n``` json\r\n{\r\n  \"name\" : \"Gailyn Bailey\",\r\n  \"cluster_name\" : \"elasticsearch\",\r\n  \"version\" : {\r\n    \"number\" : \"2.3.5\",\r\n    \"build_hash\" : \"90f439ff60a3c0f497f91663701e64ccd01edbb4\",\r\n    \"build_timestamp\" : \"2016-07-27T10:36:52Z\",\r\n    \"build_snapshot\" : false,\r\n    \"lucene_version\" : \"5.5.0\"\r\n  },\r\n  \"tagline\" : \"You Know, for Search\"\r\n}\r\n```\r\n\r\n#### Create the ES index for the posts\r\nIn the mappings part we want to differentiate between finding a hit in the title or in the body. A hit of the search in the title has twice as much value as a hit in the body.\r\n``` python\r\n#!/usr/bin/env python\r\ndata = {\r\n    \"settings\": {\r\n        \"number_of_shards\": 4,\r\n        \"number_of_replicas\": 1\r\n    },\r\n    \"mappings\": {\r\n        \"blog\": {\r\n            \"properties\": {\r\n                \"title\": { \"type\": \"string\", \"boost\": 4 },\r\n                \"body\": { \"type\": \"string\", \"boost\": 2 },\r\n            }\r\n        }\r\n    }\r\n}\r\nimport json, requests\r\nresponse = requests.put('http://127.0.0.1:9200/blog_index/', data=json.dumps(data))\r\nprint response.text\r\n```\r\n#### Add the entries\r\n``` python\r\n#!/usr/bin/env python\r\nimport json, requests\r\nfrom blog.models import Entry\r\n\r\ndata = ''\r\nfor p in Entry.objects.all():\r\n    data += '{\"index\": {\"_id\": \"%s\"}}\\n' % p.pk\r\n    data += json.dumps({\r\n        \"title\": p.title,\r\n        \"body\": p.body\r\n    })+'\\n'\r\nresponse = requests.put('http://127.0.0.1:9200/blog_index/blog/_bulk', data=data)\r\nprint response.text\r\n```\r\n#### Search the entries\r\n``` python\r\n#!/usr/bin/env python\r\nimport json, requests\r\ndata = {\r\n     \"query\": {\r\n         \"query_string\": { \"query\": \"python\" }\r\n     }\r\n}\r\nresponse = requests.post('http://127.0.0.1:9200/blog_index/blog/_search', data=json.dumps(data))\r\nprint response.json()\r\n```\r\nThis gives the following reply:\r\n``` json\r\n{\r\n  \"hits\": {\r\n    \"hits\": [\r\n      {\r\n        \"_score\": 0.63516665,\r\n        \"_type\": \"blog\",\r\n        \"_id\": \"4\",\r\n        \"_source\": {\r\n          \"body\": \"```python\\r\\n\\\"\\\"\\\" samples\\/crawl_01.py \\\"\\\"\\\"\\r\\n################################################################################\\r\\n# Application:      WebParser example 01\\r\\n# File:             samples\\/crawl_01.py\\r\\n# Goal:\\r\\n# Input:\\r\\n# Output:\\r\\n# Example:\\r\\n#\\r\\n# History:          2016-06-27 - JJ     Creation of the file\\r\\n#\r\n\r\n...\r\n\r\nmain\\r\\n################################################################################\\r\\nif __name__ == \\\"__main__\\\":\\r\\n    main()\\r\\n```\",\r\n          \"title\": \"Simple webcrawling in Python \"\r\n        },\r\n        \"_index\": \"blog_index\"\r\n      },\r\n      {\r\n        \"_score\": 0.4232868,\r\n        \"_type\": \"blog\",\r\n        \"_id\": \"7\",\r\n        \"_source\": {\r\n          \"body\": \"This is a simple script to crawl information from a website when the content is dynamically loaded.\\r\\n```\\r\\n\\\"\\\"\\\" samples\\/crawl_02.py \\\"\\\"\\\"\\r\\n################################################################################\\r\\n# Application:      WebParser example 02\\r\\n# File:             samples\\/crawl_01.py\\r\\n# Goal:             Retrieve content when JavaScript is used in page\\r\\n# Input:\\r\\n# Output:\\r\\n# Example:\\r\\n#\\r\\n# History:          2016-06-27 - JJ     Creation of the file\\r\\n\r\n\r\n...\r\n\r\nmain\\r\\n################################################################################\\r\\nif __name__ == \\\"__main__\\\":\\r\\n    main()\\r\\n```\",\r\n          \"title\": \"Webcrawling in Python using Selenium\"\r\n        },\r\n        \"_index\": \"blog_index\"\r\n      },\r\n      {\r\n        \"_score\": 0.35721725,\r\n        \"_type\": \"blog\",\r\n        \"_id\": \"13\",\r\n        \"_source\": {\r\n          \"body\": \"#### Installation\\r\\nUse the [Anaconda](https:\\/\\/www.continuum.io\\/downloads \\\"Anaconda\\\") package. It will make starting with Data Science way easier, since almost all necessary packages are included and you can start right away.\\r\\n\r\n\r\n...\r\n\r\n[Source](http:\\/\\/twiecki.github.io\\/blog\\/2014\\/11\\/18\\/python-for-data-science\\/ \\\"Twiecki@Github\\\")\",\r\n          \"title\": \"Get started with data science in Python\"\r\n        },\r\n        \"_index\": \"blog_index\"\r\n      }\r\n    ],\r\n    \"total\": 3,\r\n    \"max_score\": 0.63516665\r\n  },\r\n  \"_shards\": {\r\n    \"successful\": 4,\r\n    \"failed\": 0,\r\n    \"total\": 4\r\n  },\r\n  \"took\": 23,\r\n  \"timed_out\": false\r\n}\r\n```\r\nEach result will get a score and the results will be ordered accordingly. Of course the better the search query, the more the score will say about the likeliness of the result matching your query.", "slug": "getting-started-elasticsearch", "publish": true, "created": "2016-08-06T22:01:03.878Z", "modified": "2016-08-19T09:13:46.281Z", "tags": [6]}}, {"model": "blog.entry", "pk": 15, "fields": {"title": "Install lxml for Python on DigitalOcean", "body": "Currently I am using a DigitalOcean droplet with 512 MB to run this website. I ran into an issue when I was trying to install lxml. First make sure the correct libraries are installed before lxml is installed. \r\n``` bash\r\n$ sudo apt-get install python-dev libxml2-dev libxslt1-dev zlib1g-dev\r\n```\r\nNext, be aware that the 512 MB is not enough memory to compile the lxml package with Cython when you use pip to install, which means some additional steps are needed. To virtually increase your work memory, you could use a swapfile. Create a swapfile with these commands:\r\n\r\n``` bash\r\n$ sudo dd if=/dev/zero of=/swapfile1 bs=1024 count=524288\r\n$ sudo mkswap /swapfile1\r\n$ sudo chown root:root /swapfile1\r\n$ sudo chmod 0600 /swapfile1\r\n```\r\nNow you can use pip to install the lxml Python module\r\n``` bash\r\n$ sudo pip install lxml\r\n```\r\nAnd of course you need to clean up after installation is done.\r\n``` bash\r\n$ sudo swapoff -v /swapfile1\r\n$ sudo rm /swapfile1\r\n```", "slug": "install-lxml-python-digitalocean", "publish": true, "created": "2016-08-09T20:05:20.040Z", "modified": "2016-08-19T09:13:16.399Z", "tags": [1]}}, {"model": "blog.entry", "pk": 16, "fields": {"title": "Install Docker on Ubuntu 14.04", "body": "These are the steps needed to get Docker working on Ubuntu 14.04. I have tested these steps on a Digital Ocean droplet.\r\n\r\nFirst update the system.\r\n``` shell\r\n$ sudo apt-get update\r\n$ sudo apt-get -y upgrade\r\n```\r\nAdd the recommended package for the current kernel.\r\n``` shell\r\n$ sudo apt-get install linux-image-extra-$(uname -r)\r\n```\r\nAdd the official key for Docker.\r\n``` shell\r\n$ sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\r\n```\r\nAdd the source to the sources.list.d and refresh the packages.\r\n``` shell\r\n$ echo \"deb https://apt.dockerproject.org/repo ubuntu-trusty main\" | sudo tee /etc/apt/sources.list.d/docker.list\r\n$ sudo apt-get update\r\n```\r\nNow you can install Docker.\r\n``` shell\r\n$ sudo apt-get install docker-engine\r\n```\r\nChange the following in /etc/default/ufw:\r\n``` shell\r\nDEFAULT_APPLICATION_POLICY=\"DROP\" \r\n```\r\nbecomes\r\n``` shell\r\nDEFAULT_APPLICATION_POLICY=\"ACCEPT\" \r\n```\r\nRestart the firewall.\r\n``` shell\r\n$ sudo ufw reload\r\n```\r\nCreate a Docker group and your current user to it to be able to connect to the Docker daemon.\r\n``` shell\r\n$ sudo groupadd docker\r\n$ sudo usermod -aG docker $USER\r\n```\r\nLogin again to start using Docker. Now check if Docker is working.\r\n``` shell\r\n$ sudo service docker start\r\n$ sudo docker run hello-world\r\n```\r\nHopefully this last step will download the image and run the container. If you are happy with the result, make it start automatically on system start.\r\n``` shell\r\n$ sudo systemctl enable docker\r\n```\r\n\r\n\r\n", "slug": "install-docker-ubuntu-1404", "publish": true, "created": "2016-08-19T08:47:44.886Z", "modified": "2016-08-19T11:47:11.663Z", "tags": [7]}}, {"model": "blog.entry", "pk": 17, "fields": {"title": "Install Jira on Ubuntu 14.04", "body": "Retrieve the last Jira binary from the website. Note that you should pick the right version, either x32 or x64.\r\n``` shell\r\njitsejan@jjsvps:~/Downloads$ wget https://www.atlassian.com/software/jira/downloads/binary/atlassian-jira-software-7.2.1-x64.bin \r\n```\r\nMake the binary executable.\r\n``` shell\r\njitsejan@jjsvps:~/Downloads$ chmod a+x atlassian-jira-software-7.2.1-x64.bin \r\n```\r\nInstall the dependencies for Jira.\r\n``` shell\r\njitsejan@jjsvps:~/Downloads$ sudo \u200b\u200bapt-get install lsb-core\u200b default-jdk\u200b default-jre\r\n```\r\nExecute the binary as sudo.\r\n``` shell\r\n\u200bjitsejan@jjsvps:~/Downloads$ \u200b$ sudo ./atlassian-jira-software-7.2.1-x64.bin\r\n```\r\nStart the Jira server.\r\n``` shell\r\njitsejan@jjsvps:~/Downloads$ sudo sh /opt/atlassian/jira/bin/start-jira.sh\r\n```\r\nCreate a Jira user and database.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo -u postgres psql\r\npostgres=# CREATE DATABASE jira;\r\npostgres=# CREATE USER jira_user WITH PASSWORD 'bla';\r\npostgres=# GRANT ALL PRIVILEGES ON DATABASE jira TO jira_user;\r\n```\r\nNow go to port 8080 on your IP address and perform the set-up. After some configuration you will be able to use Jira for your projects.\r\n\r\n### Update\r\nIt could be that the server does not start. Check if the permissions are right.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo chown -R jira:jira /var/atlassian/application-data/jira\r\n\r\n```", "slug": "install-jira-ubuntu-1404", "publish": true, "created": "2016-10-04T07:09:48.915Z", "modified": "2016-10-04T13:05:09.238Z", "tags": [8, 9]}}, {"model": "blog.entry", "pk": 18, "fields": {"title": "Install Django on Ubuntu 14.04 with virtualenv, Nginx, Gunicorn and postgre", "body": "Update the system first.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo apt-get update\r\njitsejan@jjsvps:~$ sudo apt-get upgrade\r\n```\r\nInstall the virtual environment for Python.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo apt-get install python-virtualenv\r\n```\r\nCreate a new environment in a folder of your choice.\r\n``` shell\r\njitsejan@jjsvps:~$ ls /opt\r\njitsejan@jjsvps:~$ sudo virtualenv /opt/env\r\njitsejan@jjsvps:~$ sudo chown jitsejan /opt/env/\r\n```\r\nActivate the environment.\r\n``` shell\r\njitsejan@jjsvps:~$ source /opt/env/bin/activate\r\n```\r\nInstall Django inside the environment.\r\n``` shell\r\n(env)jitsejan@jjsvps:~$ pip install django\r\n(env)jitsejan@jjsvps:~$ deactivate env\r\n```\r\nInstall Postgresql on the system.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo apt-get install libpq-dev python-dev\r\njitsejan@jjsvps:~$ sudo apt-get install postgresql postgresql-contrib\r\n```\r\nInstall the Nginx webserver on the system.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo apt-get install nginx\r\n```\r\nInstall Gunicorn in the environment.\r\n``` shell\r\njitsejan@jjsvps:~$ source /opt/env/bin/activate\r\n(env)jitsejan@jjsvps:~$ sudo pip install gunicorn\r\n```\r\n\r\nCreate a database and a user for the project.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo -u postgres psql\r\npostgres=# CREATE DATABASE djang_db;\r\npostgres=# CREATE USER django_user WITH PASSWORD 'django_pass';\r\npostgres=# GRANT ALL PRIVILEGES ON DATABASE django_db TO django_user;\r\n```\r\n\r\nCreate a new project in the environment.\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env$ django-admin.py startproject django_project\r\n```\r\n\r\nInstall the Psycopg2 so PostgreSQL can be used in the application.\r\n``` shell\r\n(env)jitsejan@jjsvps:~$ sudo pip install psycopg2\r\n```\r\n\r\nAdd the database details to the settings.py\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ nano django_project/settings.py\r\n```\r\n\r\nCreate the default entries for the application in the database,\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ sudo python manage.py syncdb\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ sudo python manage.py migrate\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ sudo python manage.py makemigrations\r\n```\r\n\r\nStart the Django server.\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ sudo python manage.py runserver 0.0.0.0:8080\r\n```\r\n\r\nNow use Gunicorn to connect to the server.\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ gunicorn --bind 0.0.0.0:8080 django_project.wsgi:application\r\n```\r\n\r\nCreate a configuration file for Gunicorn.\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env$ sudo nano gunicorn_config.py\r\n``` \r\n\r\nAdd the following to the configuration file.\r\n```\r\ncommand = '/opt/env/bin/gunicorn'\r\npythonpath = '/opt/env/django_project'\r\nbind = '127.0.0.1:8088'\r\nworkers = 3\r\nuser = 'jitsejan'\r\n```\r\n\r\nUse the configuration file for starting Gunicorn.\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ gunicorn -c /opt/env/gunicorn_config.py django_project/django_project.wsgi:application\r\n```\r\n\r\nCreate a superuser for Django administration.\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ sudo ./manage.py createsuperuser\r\n```\r\n\r\nAdd the STATIC_URL to the settings.py.\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ nano django_project/settings.py\r\n```\r\n``` \r\n...\r\nSTATIC_URL = '/static/'\r\n...\r\n```\r\nNow collect the static data\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ sudo ./manage.py collectstatic\r\n```\r\nCreate a new site in Nginx for the Django project\r\n``` shell\r\njitsejan@jjsvps:~$ sudo nano /etc/nginx/sites-available/django_project\r\n```\r\nAdd the following. Change the IP address, the folder for the static files and make sure the port is the same as \r\nconfigured for Gunicorn before.\r\n```\r\nserver {\r\n    server_name 123.456.123.456, *.domain.com;\r\n\r\n    access_log off;\r\n\r\n    location /static/ {\r\n        alias /opt/env/django_project/static/;\r\n    }\r\n\r\n    location / {\r\n            proxy_pass http://127.0.0.1:8088;\r\n            proxy_set_header X-Forwarded-Host $server_name;\r\n            proxy_set_header X-Real-IP $remote_addr;\r\n            add_header P3P 'CP=\"ALL DSP COR PSAa PSDa OUR NOR ONL UNI COM NAV\"';\r\n    }\r\n}\r\n```\r\n\r\nEnable the site by adding a link in the enabled sites.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo ln -s /etc/nginx/sites-available/django_project /etc/nginx/sites-enabled/\r\n```\r\n\r\nStop Apache and start Nginx.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo service apache2 stop\r\njitsejan@jjsvps:~$ sudo service nginx start\r\n```\r\n\r\nNow run Gunicorn and visit the page in your browser.\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ gunicorn -c /opt/env/gunicorn_config.py django_project/django_project.wsgi:application\r\n```\r\nHopefully the default Django page is shown now.", "slug": "install-django-ubuntu-1404-virtualenv-nginx-gunicorn-and-postgre", "publish": true, "created": "2016-10-04T09:46:17.494Z", "modified": "2016-10-04T09:55:55.843Z", "tags": [3, 9, 10, 11, 12]}}, {"model": "blog.entry", "pk": 19, "fields": {"title": "Move Django database between servers", "body": "Save the database on the old server.\r\n``` shell\r\n(oldenv)jitsejan@oldvps:/opt/oldenv/django_project$ sudo python manage.py dumpdata blog > blog.json\r\n```\r\n\r\nLoad the data on the new server. Make sure the models for both blogs are identical.\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/env/django_project$ sudo python manage.py loaddata blog.json\r\n```", "slug": "move-django-database-between-servers", "publish": true, "created": "2016-10-04T10:05:54.088Z", "modified": "2016-10-04T10:05:54.088Z", "tags": [3]}}, {"model": "blog.entry", "pk": 20, "fields": {"title": "Install Anaconda on Ubuntu 14.04", "body": "Retrieve the last Anaconda version for your system (32 or 64 bit).\r\n``` shell\r\njitsejan@jjsvps:~$ cd Downloads/\r\njitsejan@jjsvps:~/Downloads$ wget https://repo.continuum.io/archive/Anaconda2-4.1.1-Linux-x86_64.sh\r\n```\r\n\r\nRun the installer.\r\n``` shell\r\njitsejan@jjsvps:~/Downloads$ bash Anaconda2-4.1.1-Linux-x86_64.sh \r\n```\r\n\r\nUpdate the terminal to include the Anaconda references.\r\n``` shell\r\njitsejan@jjsvps:~/Downloads$ source ~/.bashrc\r\n```\r\n\r\nTest if iPython is working now.\r\n``` shell\r\njitsejan@jjsvps:~$ ipython -v\r\n```\r\n\r\nAll set.", "slug": "install-anaconda-ubuntu-1404", "publish": true, "created": "2016-10-04T10:29:51.713Z", "modified": "2016-10-04T11:25:01.402Z", "tags": [9, 13]}}, {"model": "blog.entry", "pk": 21, "fields": {"title": "Check the listening ports on the server", "body": "Use netstat to check with ports are listening on the machine.\r\n``` shell\r\njitsejan@jjsvps:~$ netstat -lnt | awk '$6 == \"LISTEN\"'\r\n```", "slug": "check-listening-ports-on-server", "publish": true, "created": "2016-10-04T11:24:03.197Z", "modified": "2016-10-04T11:24:33.365Z", "tags": [9]}}, {"model": "blog.entry", "pk": 22, "fields": {"title": "Using Supervisor to start Gunicorn", "body": "To avoid running the Gunicorn in a separate screen, you can use Supervisor to automatically start\r\nthe Gunicorn server on system start or on user demand.\r\n\r\nInstall Supervisor.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo pip install supervisor\r\n```\r\n\r\nCreate the default configuration file for Supervisor.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo echo_supervisord_conf > /etc/supervisord.conf\r\n```\r\n\r\nCreate the configuration file for the website.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo nano /etc/supervisor/conf.d/website.conf\r\n```\r\nEnter the following.\r\n```\r\n; /etc/supervisor/conf.d/website.conf\r\n[program:website]\r\ncommand=gunicorn -c /opt/env/gunicorn_config.py django_project.wsgi:application\r\ndirectory=/opt/env/django_project/\r\nuser=jitsejan\r\nautostart=True\r\nautorestart=True\r\nredirect_stderr=True\r\n```\r\n\r\nMake the file executable.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo chmod a+x /etc/supervisor/conf.d/website.conf \r\n```\r\n\r\nReload Supervisor to find the new file and update the configuration.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo supervisorctl reread\r\njitsejan@jjsvps:~$ sudo supervisorctl update\r\n```\r\n\r\nNow you can start the website with the following command.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo supervisorctl start website\r\n```", "slug": "using-supervisor-start-gunicorn", "publish": true, "created": "2016-10-04T14:06:45.799Z", "modified": "2016-10-04T14:07:25.003Z", "tags": [10, 14]}}, {"model": "blog.entry", "pk": 23, "fields": {"title": "Upgrade PostgreSQL", "body": "By default Ubuntu 14.04 is running PostgreSQL version 9.3. In order to use the json datatype PostgreSQL \r\nversion 9.4 or bigger is needed. The versions can be installed side by side, but for clarity you could remove the \r\nolder/wrong versions.\r\n\r\nFirst check which PostgreSQL is running\r\n``` shell\r\njitsejan@jjsvps:~$ sudo service postgresql status\r\n```\r\nProbably this will list version 9.3 running on port 5432.\r\n\r\nAdd the PostgreSQL repository to the sources to be able to update to newer versions.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo sh -c 'echo \"deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main\" > /etc/apt/sources.list.d/pgdg.list'\r\njitsejan@jjsvps:~$ wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\r\n```\r\nNow update the system to retrieve data from the new repository.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo apt-get update\r\njitsejan@jjsvps:~$ sudo apt-get upgrade\r\n```\r\n\r\nNext we can install version 9.4 of PostgreSQL.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo apt-get install postgresql-9.4\r\n```\r\n\r\nIf you check the status again, you will see two instances of PostgreSQL running.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo service postgresql status\r\n```\r\n\r\nOptionally the old version can be removed.\r\n``` shell\r\njitsejan@jjsvps:~$ sudo apt-get remove --purge postgresql-9.3\r\n```", "slug": "upgrade-postgresql", "publish": true, "created": "2016-10-05T08:21:35.912Z", "modified": "2016-10-05T08:21:35.912Z", "tags": [9, 15]}}, {"model": "blog.entry", "pk": 24, "fields": {"title": "Install Java version 8", "body": "I ran into an issue while re-configuring the Jira installation on my system. After an update Java 8 was needed but it is not present by default on Ubuntu 14.04. To install the JRE and JDK you need to add the repository of the webupd8team and use the Oracle Java 8 installer.\r\n\r\nInstall the common software-properties to be able to use the add-app-repository command.\r\n ``` shell\r\n jitsejan@jjsvps:~$ sudo apt-get install software-properties-common\r\n ```\r\n \r\n Add the Java repository to the Ubuntu sources.\r\n ``` shell\r\n jitsejan@jjsvps:~$ sudo add-apt-repository ppa:webupd8team/java\r\n ```\r\n \r\n Update the sources to retrieve the new Java repository.\r\n ``` shell\r\n jitsejan@jjsvps:~$ sudo apt-get update\r\n ```\r\n \r\n Install Java version 8.\r\n ``` shell\r\n jitsejan@jjsvps:~$ sudo apt-get install oracle-java8-installer\r\n ```", "slug": "install-java-version-8", "publish": false, "created": "2016-10-05T08:28:50.245Z", "modified": "2016-10-05T08:28:50.245Z", "tags": [9, 16]}}, {"model": "blog.entry", "pk": 25, "fields": {"title": "Change PostgreSQL database encoding", "body": "I ran into an issue where I couldn't save some JSON-data to the database because of a weird UTF8 character. Apparently my databases have the SQL ASCII encoding and not the necessary UTF8 encoding.\r\n\r\nFirst login to the PostgreSQL shell.\r\n``` shell\r\n(env)jitsejan@jjsvps:/opt/canadalando_env/canadalando_django$ sudo -u postgres psql\r\n```\r\n\r\nCheck the list of databases.\r\n``` shell\r\npostgres=# \\l\r\n```\r\nHere I could see my database had the wrong encoding, instead of SQL_ASCII I want UTF8. \r\nI dropped the database so I can re-create it with the right encoding. Note that I did NOT make a back-up, since my database was still empty.\r\n\r\n``` shell\r\npostgres=# DROP DATABASE website_db;\r\n```\r\n\r\nIn order to use UTF8 the template for the databases needs to be updated first.\r\n\r\nDisable the template1.\r\n``` shell\r\npostgres=# UPDATE pg_database SET datistemplate = FALSE WHERE datname ='template1';                                                                                                                                                                                                                                 \r\n```\r\n\r\nDrop the database.\r\n``` shell\r\npostgres=# DROP DATABASE template1;\r\n```\r\n\r\nNow re-create it with the right encoding.\r\n``` shell\r\npostgres=# CREATE DATABASE template1 WITH TEMPLATE = template0 ENCODING = 'UNICODE';\r\n```\r\n\r\nActivate the template.\r\n``` shell\r\npostgres=# UPDATE pg_database SET datistemplate = TRUE WHERE datname = 'template1';\r\n```\r\n\r\nNow we can re-create the database that we dropped earlier.\r\n``` shell\r\npostgres=# CREATE DATABASE website_db WITH ENCODING 'UNICODE';\r\n```", "slug": "change-postgresql-database-encoding", "publish": true, "created": "2016-10-06T08:25:42.174Z", "modified": "2016-10-16T23:52:34.334Z", "tags": [15]}}, {"model": "blog.website", "pk": 1, "fields": {"title": "MultyEPDM", "description": "The website from Multy EPDM is a website a took over from another administrator. The layout was designed by the previous administrator. I \u2018only\u2019 changed the page structure, rewrote the whole menu and corrected the content of all the pages. Besides that I made the page easier to work with, so the prices can be easily adjusted by the owner of the company. Finally I created a new form which automatically calculated the materials needed for the roof based on the dimensions. Unfortunately somebody else took over the website and made it less appealing again.", "slug": "site-multyepdm", "image": "images/site-multy-epdm.png", "link": "http://www.multyepdm.nl", "publish": true, "created": "2016-07-30T19:33:32.875Z", "modified": "2016-07-30T20:42:19.735Z"}}, {"model": "blog.website", "pk": 2, "fields": {"title": "Lichtkoepeldump.nl", "description": "Lichtkoepeldump.nl is another website I took over from another administrator. I didn\u2019t create the design, but I rewrote the whole underlying code for the website. Apart from this code I changed the price lists for the different products on the Lichtkoepel Dump. The website was full of errors, which was ideal for me since I could get familiar with HTML and CSS standards.", "slug": "site-lichtkoepeldump", "image": "images/site-lichtkoepeldump.png", "link": "http://www.lichtkoepeldump.nl", "publish": true, "created": "2016-07-30T20:19:05.213Z", "modified": "2016-07-30T20:45:33.079Z"}}, {"model": "blog.website", "pk": 4, "fields": {"title": "Cafe Eigenwijs", "description": "Cafe Eigenwijs, a cafe in it\u2019s own way, in the centre of Haaren. Update: Since March 2011 the cafe is closed and the website is offline. This website was build in March 2010. It is the first webpage I\u2019ve created for a company. I made my own content management system to make it easier for the owner of the cafe to add new activities and news, to upload pictures and to adjust the opening hours.", "slug": "site-cafe-eigenwijs", "image": "images/site-cafe-eigenwijs.png", "link": "-", "publish": true, "created": "2016-07-30T20:37:03.305Z", "modified": "2016-07-30T20:45:39.844Z"}}, {"model": "blog.website", "pk": 5, "fields": {"title": "Borgo San Giovanni", "description": "This is the second website I made for/with a client, building it from the ground up. It is meant to replace the old website, since it was cluttered and not appealing. I tried to make it a clean and clear website, while keeping it visually appealing for visitors. The website is available in 3 different languages, English, Dutch and Italian. The owners of the website can access the language files themselves and add translations as they wish. Update Spring 2013: The website that I created has been replaced by a new website to work with the agency they are currently working with. The images and text that I selected and changed have been transferred to the new website luckily. On the link the \u2018naked\u2019 version can still be viewed.", "slug": "site-borgo-san-giovanni", "image": "images/Home-Borgo-San-Giovanni.png", "link": "-", "publish": true, "created": "2016-07-30T20:38:35.526Z", "modified": "2016-07-30T20:45:45.985Z"}}, {"model": "blog.website", "pk": 6, "fields": {"title": "Econex", "description": "After returning from my stay in South-Africa I was asked to work on the company website of my former flatmate. The old website, which is still online, looks old fashioned and publications and other research work should be found easier. The whole website was restructured to find the practise areas, sectors, publications and people who work there faster.\r\n\r\n\r\nFor me the big challenge lays in the fact I had to make a whole new database structure to link the publications to its corresponding areas, sectors and people and make the whole publication database searchable. Design was done by Shingi Nhari, but implementation was done by me. The front-end was finished in a few weeks, but the back-end took a while to finish. Luckily I finished before the deadline, but, as always in Africa, things move a little bit slow. The website is not officially online yet (Dec, 2013), but in the background the new website can be visited. \r\n\r\n\r\nUpdate Oct, 2015: The website has been updated. My code was used and the design has been updated.", "slug": "site-econex", "image": "images/Home-Econex.png", "link": "http://econex.co.za", "publish": true, "created": "2016-07-30T20:49:56.482Z", "modified": "2016-07-30T20:51:28.121Z"}}, {"model": "blog.website", "pk": 7, "fields": {"title": "Sweet Surprise Nuenen", "description": "Sweet Surprise is a candy shop in Nuenen. The owners asked me to redo their website with some big changes. The frontpage should show what Sweet Surprise is all about, people should be able to book a kids party and there should be a webshop with all the candy and presents. The frontpage has been upgraded, the booking system and the contact form work and the webshop contains all the products. Apart from that, they also wanted to control the content and add images without needing external help. Therefore, to create the website I have used WordPress combined with the Mantra theme and several plugins, namely\r\n\r\n- Booking Calendar\r\n- FancyBox for WordPress\r\n- Fast Secure Contact Form\r\n- ICEPAY Plugin for Woocommerce\r\n- MapPress Easy Google Maps\r\n- Widget Logic\r\n- WooCommerce\r\n- WooCommerce (nl)\r\n\r\nI have delivered the website in 2013. Since then the owners are maintaining the website themselves.", "slug": "site-sweet-surprise-nuenen", "image": "images/Home-Sweet-Surprise-Nuenen.png", "link": "http://www.sweetsurprisenuenen.nl", "publish": true, "created": "2016-07-30T21:01:28.349Z", "modified": "2016-07-30T21:01:28.349Z"}}, {"model": "blog.website", "pk": 8, "fields": {"title": "Fresh of the Press", "description": "Another website for South-Africa. This one is a blog by two girls about wine. Shingi Nhari did the design and I am the one that implemented it. The website is not online officially, but can be viewed on my local copy in my own domain. It should still be finished up by the owners, but my work is done. [Nov 2013]\r\n\r\n", "slug": "site-fresh-of-the-press", "image": "images/Fresh-of-The-Press-Home-534x1024.png", "link": "-", "publish": true, "created": "2016-07-30T21:03:30.912Z", "modified": "2016-07-30T21:03:30.912Z"}}, {"model": "blog.website", "pk": 9, "fields": {"title": "Ben Cuypers", "description": "Ben Cuypers is a painting and maintenance company in Valkenswaard. Because they want to be independent of the web admin (and pay less) they asked me to create a simple webpage which they could easily maintain. I have created this website in WordPress with the Vantage theme and the Page Builder plugin because I believe that is the easiest way to put together an appealing website which is not complicated to maintain. Instead of writing a manual, I\u201dve created a number of screencasts for the company to explain how to use the website. They can now watch the instructions on YouTube and reproduce the steps I show in the video to edit the content and add new media to their webpage. \r\n\r\n\r\nDelivered in October 2014.", "slug": "site-ben-cuypers", "image": "images/B.-Cuypers-Glas-en-Schildersbedrijf-935x1024.png", "link": "http://www.b-cuypers.nl", "publish": true, "created": "2016-07-30T21:04:41.472Z", "modified": "2016-07-30T21:04:41.472Z"}}, {"model": "blog.project", "pk": 1, "fields": {"title": "3D Mario with Blender", "description": "In this project I turned a 2 dimensional Mario into a 3 dimensional Mario. I started with an image of 17\u00d717 pixels and used Blender\u00ae to create the 3D Mario. \r\n\r\n[Summer 2009]", "slug": "project-3d-mario", "image": "images/3DMario1.png", "link": "-", "publish": true, "created": "2016-07-30T21:28:33.009Z", "modified": "2016-07-30T21:28:33.010Z"}}, {"model": "blog.project", "pk": 2, "fields": {"title": "Remote control simulation", "description": "In 2007 I started using a remote control to control the media player on my computer. In November 2009 the use extended to controlling the music, video, sound and different lights on my room. I created a simulation of the remote control, so when I click the buttons in the simulation on my computer, it will start and stop the music mimicking the behavior of the remote control.", "slug": "project-remote", "image": "images/Remote_5903_sim.png", "link": "-", "publish": true, "created": "2016-07-30T21:29:44.451Z", "modified": "2016-07-30T21:29:44.451Z"}}, {"model": "blog.project", "pk": 3, "fields": {"title": "Phone project", "description": "My bachelor thesis was a research on how to use a mobile phone to control a computer by moving the phone. For this I needed to make a connection between the phone and the computer and send the data about the movement of the phone over link to the computer. The computer can apply the intended action by processing the received data. Communication was done over a Bluetooth link. I developed the software for both the client and the server and tested it on several platforms (Windows, Linux).", "slug": "project-phone", "image": "images/phone_hand.jpg", "link": "-", "publish": true, "created": "2016-07-30T21:30:53.820Z", "modified": "2016-07-30T21:30:53.820Z"}}, {"model": "blog.project", "pk": 4, "fields": {"title": "Aho-Corasick on the FPGA", "description": "My internship research in Stellenbosch, SA aimed at the recognition of patterns of strings in data. Dedicated hardware in combination with the Aho-Corasick algorithm was used to find occurrences of words in network data. This way unwanted network traffic, e.g. mail, could be detected before it reached the personal computer of the end user. The research focused on a speed comparison between a normal desktop computer and a field-programmable gate array (FPGA). It turned out that for sufficiently large strings, the FPGA outperformed the desktop computer.", "slug": "project-aho-corasick", "image": "images/07032012407_thumb.jpg", "link": "-", "publish": true, "created": "2016-07-30T21:31:34.745Z", "modified": "2016-07-30T21:31:34.745Z"}}, {"model": "blog.project", "pk": 5, "fields": {"title": "Monitoring eating behavior", "description": "My graduation project focused on an automatic way of recognising intake moments of a person based on data from different sensors. I used two accelerometers to monitor the arm movements and an in-ear microphone to monitor the sounds of the jaw bone. Based on the recorded data of different persons during the day, I made a classifier in Matlab to automatically find intake moments in the data. For the recognition algorithm I used different feature selectors and classifiers to compare the performance of the classification. It turned out that the intake of drinks is the easiest movement to recognise, while intake using cutlery, especially forks, is difficult to be found in the data. Apart from the cutlery used, it turned out that taller people had better classification results because their long arms make the intake movement more clear.", "slug": "project-monitoring-eating", "image": "images/ADM_James_sensors.png", "link": "-", "publish": true, "created": "2016-07-30T21:32:49.253Z", "modified": "2016-07-30T21:32:49.253Z"}}, {"model": "blog.project", "pk": 6, "fields": {"title": "Hongerdoeken", "description": "This is a project where I made a Flash application with information about hongerdoeken. In October 2010 this application was distributed together with the corresponding book through the Netherlands. The online version doesn\u2019t contain the correct contents, but the functionality is up-to-date.", "slug": "project-hongerdoeken", "image": "images/project-hongerdoeken.png", "link": "-", "publish": true, "created": "2016-07-30T21:34:39.748Z", "modified": "2016-07-30T21:34:39.748Z"}}